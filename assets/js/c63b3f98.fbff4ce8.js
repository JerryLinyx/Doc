"use strict";(self.webpackChunkmy_web=self.webpackChunkmy_web||[]).push([[455],{1292:(e,n,i)=>{i.d(n,{A:()=>r});const r=i.p+"assets/files/RealTraceGenerator_of_Llama3.2_3B_Conversational-7195c7822262731bd84c8b0c3158e3e1.ipynb"},3390:(e,n,i)=>{i.d(n,{A:()=>r});const r=i.p+"assets/images/GPU power-f564070c0edece6c7d383b4ad1ac8d73.png"},5535:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"PACC/PACC","title":"Power-Aware Collective Communication","description":"Contributors","source":"@site/docs/PACC/PACC.mdx","sourceDirName":"PACC","slug":"/PACC/","permalink":"/Doc/docs/PACC/","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/PACC/PACC.mdx","tags":[],"version":"current","sidebarPosition":50,"frontMatter":{"sidebar_label":"PACC","sidebar_position":50},"sidebar":"tutorialSidebar","previous":{"title":"PACC","permalink":"/Doc/docs/category/pacc"},"next":{"title":"Tutorial Intro","permalink":"/Doc/docs/intro"}}');var s=i(4848),l=i(8453);const t={sidebar_label:"PACC",sidebar_position:50},a="Power-Aware Collective Communication",o={},d=[{value:"Contributors",id:"contributors",level:2},{value:"Abstract",id:"abstract",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Project Goal",id:"project-goal",level:3},{value:"Description",id:"description",level:3},{value:"How to access",id:"how-to-access",level:4},{value:"Hardware dependencies",id:"hardware-dependencies",level:4},{value:"Software dependencies",id:"software-dependencies",level:4},{value:"Datasets and Models",id:"datasets-and-models",level:4},{value:"Roadmap",id:"roadmap",level:3},{value:"1. Real Training Framework",id:"1-real-training-framework",level:2},{value:"Goals",id:"goals",level:4},{value:"Environment Setup",id:"environment-setup",level:4},{value:"Why Unsloth",id:"why-unsloth",level:4},{value:"Run Instruction",id:"run-instruction",level:4},{value:"Results Sample",id:"results-sample",level:4},{value:"Example Outputs",id:"example-outputs",level:3},{value:"2. Simulation Framework",id:"2-simulation-framework",level:2},{value:"2.1 Chakra ET Generation and ASTRA-Sim Integration (Shufeng Chen)",id:"21-chakra-et-generation-and-astra-sim-integration-shufeng-chen",level:3},{value:"Goals",id:"goals-1",level:4},{value:"Environment Setup",id:"environment-setup-1",level:4},{value:"Installation",id:"installation",level:4},{value:"Generating ET Files",id:"generating-et-files",level:4},{value:"2.2 ASTRA-Sim Analytical Simulation and Integration",id:"22-astra-sim-analytical-simulation-and-integration",level:3},{value:"Setup ASTRA-Sim \u2014 Installation",id:"setup-astra-sim--installation",level:4},{value:"Build ASTRA-sim",id:"build-astra-sim",level:4},{value:"Run ASTRA-sim",id:"run-astra-sim",level:4},{value:"Benchmark Reference \u2014 MLPerf Power",id:"benchmark-reference--mlperf-power",level:2},{value:"Licenses",id:"licenses",level:2},{value:"References",id:"references",level:2}];function c(e){const n={a:"a",blockquote:"blockquote",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"power-aware-collective-communication",children:"Power-Aware Collective Communication"})}),"\n",(0,s.jsx)(n.h2,{id:"contributors",children:"Contributors"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Yuxuan Lin"})," \xb7 ",(0,s.jsx)(n.a,{href:"mailto:yl6061@columbia.edu",children:"yl6061@columbia.edu"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Jiayu Zhou"})," \xb7 ",(0,s.jsx)(n.a,{href:"mailto:jz4019@columbia.edu",children:"jz4019@columbia.edu"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Shufeng Chen"})," \xb7 ",(0,s.jsx)(n.a,{href:"mailto:sc5739@columbia.edu",children:"sc5739@columbia.edu"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Boxiong Li"})," \xb7 ",(0,s.jsx)(n.a,{href:"mailto:bl3155@columbia.edu",children:"bl3155@columbia.edu"})]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"abstract",children:"Abstract"}),"\n",(0,s.jsx)(n.p,{children:"This artifact supports our work on improving the energy efficiency of distributed LLM training through power-aware communication. It consists of two primary components:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A Real-World Trace Collection Framework: A Google Colab notebook that uses Unsloth and the PyTorch Profiler to generate detailed execution and power traces from fine-tuning a Llama 3 model on a single GPU."}),"\n",(0,s.jsx)(n.li,{children:"A Simulation Framework: A set of scripts and configurations for using Symbolic Tensor Graph (STG) to generate synthetic yet realistic MLPerf-like workload traces and running them with the ASTRA-Sim 2.0 analytical backend to simulate distributed training."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The artifacts allow for the reproduction of our foundational workflows: (1) capturing operator-level traces from real hardware and (2) simulating a distributed setup using generated traces. Minimal requirements include a Google account for the Colab portion and Docker for the simulation part."}),"\n",(0,s.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(n.h3,{id:"project-goal",children:"Project Goal"}),"\n",(0,s.jsxs)(n.p,{children:["Large Language Model (LLM) training at scale requires hundreds to thousands of GPUs.",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.strong,{children:"Collective communication"})," (e.g., AllReduce) dominates both training ",(0,s.jsx)(n.strong,{children:"performance"})," and ",(0,s.jsx)(n.strong,{children:"energy cost"}),". Our project aims to ",(0,s.jsx)(n.strong,{children:"reduce communication energy overhead"})," through ",(0,s.jsx)(n.strong,{children:"power-aware communication"}),", focusing on ",(0,s.jsx)(n.strong,{children:"DVFS (Dynamic Voltage and Frequency Scaling)"})," during the communication phase \u2014 without sacrificing performance."]}),"\n",(0,s.jsx)(n.h3,{id:"description",children:"Description"}),"\n",(0,s.jsx)(n.h4,{id:"how-to-access",children:"How to access"}),"\n",(0,s.jsx)(n.p,{children:"The artifact is hosted in a GitHub repository. You will need to clone the repository to access the scripts and documentation."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/EECS6894/power-aware-communication.git\ncd power-aware-communication\n"})}),"\n",(0,s.jsx)(n.h4,{id:"hardware-dependencies",children:"Hardware dependencies"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Real-World Trace Collection Framework: Requires access to an NVIDIA Tesla T4 GPU (15 GB), available via the Google Colab free tier. It should also work on other GPUs with similar or greater memory capacity."}),"\n",(0,s.jsx)(n.li,{children:"Simulation Framework: Requires no specialized hardware. It will run on Docker. The ASTRA-Sim analytical backend does not rely on GPUs."}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"software-dependencies",children:"Software dependencies"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Real-World Trace Collection Framework: All dependencies (PyTorch, Unsloth, etc.) are installed automatically within the Google Colab notebook. No local setup is needed."}),"\n",(0,s.jsx)(n.li,{children:"Simulation Framework: Requires a working Docker installation. All other dependencies (C++ compiler, Python, ASTRA-Sim, STG) are containerized in the provided Dockerfile and will be built into the image."}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"datasets-and-models",children:"Datasets and Models"}),"\n",(0,s.jsx)(n.p,{children:"Both the dataset used for fine-tuning and the Llama 3.2 3B base model are downloaded automatically from the HuggingFace Hub when the Colab notebook is executed. No manual downloads are required. No external datasets or models are needed for the simulation workflow."}),"\n",(0,s.jsx)(n.h3,{id:"roadmap",children:"Roadmap"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Stage"}),(0,s.jsx)(n.th,{children:"Task"}),(0,s.jsx)(n.th,{children:"Contribution"}),(0,s.jsx)(n.th,{children:"Status"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"#22-astra-sim-analytical-simulation-and-integration",children:"ASTRA-Sim setup"})}),(0,s.jsx)(n.td,{children:"Analytical backend"}),(0,s.jsx)(n.td,{children:"All"}),(0,s.jsx)(n.td,{children:"\u2705 Done"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"#1-real-training-framework",children:"Real trace collection"})}),(0,s.jsxs)(n.td,{children:["PyTorch Profiler + Unsloth (See ",(0,s.jsx)(n.a,{href:"#results-sample",children:"Results Sample"}),")"]}),(0,s.jsx)(n.td,{children:"Yuxuan Lin, Jiayu Zhou"}),(0,s.jsx)(n.td,{children:"\u2705 Done"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.a,{href:"#2-simulation-framework",children:"Chakra ET generation"})}),(0,s.jsx)(n.td,{children:"For ASTRA-Sim input"}),(0,s.jsx)(n.td,{children:"Shufeng Chen, Boxiong Li"}),(0,s.jsx)(n.td,{children:"\u2705 Done"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Power modeling"}),(0,s.jsx)(n.td,{children:"DVFS-aware communication"}),(0,s.jsx)(n.td,{children:"All"}),(0,s.jsx)(n.td,{children:"\ud83d\udfe1 In progress"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"ASTRA-Sim Integration"}),(0,s.jsx)(n.td,{children:"Power-aware backend"}),(0,s.jsx)(n.td,{children:"All"}),(0,s.jsx)(n.td,{children:"\ud83d\udfe1 In progress"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Evaluation"}),(0,s.jsx)(n.td,{children:"EDP + Samples/J"}),(0,s.jsx)(n.td,{children:"TBD"}),(0,s.jsx)(n.td,{children:"\ud83d\udd1c Planned"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"1-real-training-framework",children:"1. Real Training Framework"}),"\n",(0,s.jsxs)(n.p,{children:["We use ",(0,s.jsx)(n.a,{href:"https://github.com/unslothai/unsloth",children:(0,s.jsx)(n.strong,{children:"Unsloth"})})," as the real training backend for efficient LLM profiling and trace collection."]}),"\n",(0,s.jsx)(n.h4,{id:"goals",children:"Goals"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Collect ",(0,s.jsx)(n.strong,{children:"PyTorch Profiler Execution Traces"})," during actual fine-tuning runs."]}),"\n",(0,s.jsxs)(n.li,{children:["Record ",(0,s.jsx)(n.strong,{children:"compute events"}),", memory usage, shapes, and execution timelines."]}),"\n",(0,s.jsx)(n.li,{children:"Generate high-resolution traces to support energy/performance co-analysis."}),"\n",(0,s.jsxs)(n.li,{children:["Provide a reproducible ",(0,s.jsx)(n.strong,{children:"trace-driven workflow"})," for downstream simulation and optimization."]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"environment-setup",children:"Environment Setup"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Host:"})," ",(0,s.jsx)(n.a,{href:"https://colab.research.google.com/",children:"Google Colab"})," (Free tier)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"GPU:"})," Tesla T4 (15 GB)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Framework:"})," ",(0,s.jsx)(n.a,{href:"https://pytorch.org/",children:"PyTorch"})," + ",(0,s.jsx)(n.a,{href:"https://github.com/unslothai/unsloth",children:"Unsloth"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Installation:"})," No Conda required; all dependencies installed via notebook."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Setup time:"})," \u2264 5 minutes (from notebook open to first run)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Profiling duration:"})," \u2264 1 minute per run"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Resource usage:"})," See the table below (measured on Colab T4)"]}),"\n"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Resource"}),(0,s.jsx)(n.th,{style:{textAlign:"right"},children:"Used"}),(0,s.jsx)(n.th,{style:{textAlign:"right"},children:"Total"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"System RAM"}),(0,s.jsx)(n.td,{style:{textAlign:"right"},children:"8.3 GB"}),(0,s.jsx)(n.td,{style:{textAlign:"right"},children:"12.7 GB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"GPU RAM"}),(0,s.jsx)(n.td,{style:{textAlign:"right"},children:"10.8 GB"}),(0,s.jsx)(n.td,{style:{textAlign:"right"},children:"15.0 GB"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Disk"}),(0,s.jsx)(n.td,{style:{textAlign:"right"},children:"46.1 GB"}),(0,s.jsx)(n.td,{style:{textAlign:"right"},children:"235.7 GB"})]})]})]}),"\n",(0,s.jsx)(n.h4,{id:"why-unsloth",children:"Why Unsloth"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Memory-efficient fine-tuning, enabling profiling on limited GPU resources."}),"\n",(0,s.jsx)(n.li,{children:"Native support for PyTorch Profiler integration."}),"\n",(0,s.jsx)(n.li,{children:"Compatible with multiple LLM architectures (e.g., LLaMA, Mistral, Gemma)."}),"\n",(0,s.jsx)(n.li,{children:"Easy to reproduce in Colab environments."}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"run-instruction",children:"Run Instruction"}),"\n",(0,s.jsxs)(n.p,{children:["Please open and run our ",(0,s.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:i(1292).A+"",children:"Colab Notebook"})," on a ",(0,s.jsx)(n.strong,{children:"free Tesla T4 Colab instance"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Navigate to ",(0,s.jsx)(n.strong,{children:"Runtime \u2192 Run all"}),"."]}),"\n",(0,s.jsx)(n.li,{children:"All dependencies will be installed automatically."}),"\n",(0,s.jsxs)(n.li,{children:["Generated traces will include both ",(0,s.jsx)(n.strong,{children:"PyTorch profiler"})," and ",(0,s.jsx)(n.strong,{children:"NVML power"})," logs."]}),"\n"]}),"\n",(0,s.jsxs)("div",{children:[(0,s.jsx)("a",{href:"https://unsloth.ai/",children:(0,s.jsx)("img",{src:"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png",alt:"Unsloth logo",width:"115"})}),(0,s.jsx)("a",{children:" \xa0"}),(0,s.jsx)("a",{href:"https://docs.unsloth.ai/",children:(0,s.jsx)("img",{src:"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true",alt:"Unsloth documentation",width:"125"})})]}),"\n",(0,s.jsx)(n.h4,{id:"results-sample",children:"Results Sample"}),"\n",(0,s.jsx)(n.p,{children:"On Colab, you can check available trace by:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"%ls /content/gdrive/MyDrive/llama32_profile/trace\n\n<some-random-number>.pt.trace.json\npower_log.csv\n"})}),"\n",(0,s.jsx)(n.h3,{id:"example-outputs",children:"Example Outputs"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://drive.google.com/file/d/13LliOcmkRFrh-EB0DSvBzAP1Fw3UGRa9/view?usp=drive_link",children:(0,s.jsx)(n.strong,{children:"some-random-number.pt.trace.json"})})," \u2014 PyTorch profiler execution trace (Chrome trace format)"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Top 10 Operations",src:i(5745).A+"",width:"1389",height:"490"})}),"\n",(0,s.jsx)("small",{children:(0,s.jsx)("em",{children:"The figure shows top 10 operations by duration."})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:i(6210).A+"",children:(0,s.jsx)(n.strong,{children:"power_log.csv"})})," \u2014 Raw NVML power log with timestamp, power (W), GPU & memory utilization."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"GPU Power Trace",src:i(3390).A+"",width:"1190",height:"390"})}),"\n",(0,s.jsx)("small",{children:(0,s.jsx)("em",{children:"The figure shows the GPU power consumption curve aligned with the profiler timeline."})}),"\n",(0,s.jsx)(n.h2,{id:"2-simulation-framework",children:"2. Simulation Framework"}),"\n",(0,s.jsx)(n.p,{children:"We simulate communication and power behavior with:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://github.com/astra-sim",children:(0,s.jsx)(n.strong,{children:"ASTRA-Sim"})}),": communication and system-level simulator"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://github.com/astra-sim/symbolic_tensor_graph",children:(0,s.jsx)(n.strong,{children:"Symbolic Tensor Graph"})}),": lightweight ET trace format for scalable simulations"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Why Simulation"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Real hardware measurements are expensive and slow at scale."}),"\n",(0,s.jsx)(n.li,{children:"Simulation allows rapid design-space exploration and power modeling."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Features we leverage"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Analytical backend support"}),"\n",(0,s.jsx)(n.li,{children:"Multi-dimensional topology modeling"}),"\n",(0,s.jsx)(n.li,{children:"Scheduling and overlap policy tuning"}),"\n",(0,s.jsx)(n.li,{children:"Trace-driven energy/performance estimation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://astra-sim.github.io/",children:"ASTRA-Sim Docs"})}),"\n",(0,s.jsx)(n.h3,{id:"21-chakra-et-generation-and-astra-sim-integration-shufeng-chen",children:"2.1 Chakra ET Generation and ASTRA-Sim Integration (Shufeng Chen)"}),"\n",(0,s.jsxs)(n.p,{children:["This component focuses on integrating ",(0,s.jsx)(n.strong,{children:"Symbolic Tensor Graph (STG)"})," with ",(0,s.jsx)(n.strong,{children:"ASTRA-Sim"})," to generate workload traces for simulation."]}),"\n",(0,s.jsx)(n.h4,{id:"goals-1",children:"Goals"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Generate ",(0,s.jsx)(n.strong,{children:"Chakra Execution Trace (ET)"})," and ",(0,s.jsx)(n.strong,{children:"communicator"})," files for LLM workloads (e.g., LLaMA3, BERT)."]}),"\n",(0,s.jsx)(n.li,{children:"Run ASTRA-Sim analytical simulations using the generated traces."}),"\n",(0,s.jsx)(n.li,{children:"Establish a reproducible workflow for trace-driven performance and energy analysis."}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"environment-setup-1",children:"Environment Setup"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Host:"})," Windows 11"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Environment:"})," Ubuntu (via Docker)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Tools:"})," ",(0,s.jsx)(n.a,{href:"https://github.com/astra-sim/astra-sim",children:"ASTRA-Sim"})," \xb7 ",(0,s.jsx)(n.a,{href:"https://github.com/astra-sim/symbolic_tensor_graph",children:"Symbolic Tensor Graph"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Installation:"})," Follow both tools\u2019 official setup guides (no Conda required)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Setup time:"})," \u2264 30 minutes (from environment setup to first successful run)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Run time per simulation:"})," ~2\u20133 minutes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Resource usage:"})," RAM \u2248 0.97 GB, Disk \u2248 5.3 GB used in author's run (within Docker container; ensure \u2265 6 GB free space)"]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"installation",children:"Installation"}),"\n",(0,s.jsx)(n.p,{children:"To set up the environment and install the required dependencies, follow these steps:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Clone the repository from symbolic_tensor_graph\ngit clone git@github.com:astra-sim/symbolic_tensor_graph.git\n\n# Navigate to the project directory\ncd symbolic_tensor_graph\n\n# Install dependencies via conda\nconda create -n <env_name>\nconda activate <env_name>\nconda install numpy sympy python-graphviz protobuf pandas -c conda-forge\n"})}),"\n",(0,s.jsx)(n.h4,{id:"generating-et-files",children:"Generating ET Files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 main.py \\\n  --output_dir generated/llama3_7b_simple \\\n  --output_name workload.%d.et \\\n  --dp 1 --tp 1 --pp 1 --sp 1 \\\n  --model_type llama \\\n  --dmodel 4096 --head 32 --kvhead 8 --dff 11008 \\\n  --seq 2048 --batch 4 --num_stacks 32 \\\n  --mixed_precision True \\\n  --chakra_schema_version v0.0.4\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Parameters Used"})}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Parameter"}),(0,s.jsx)(n.th,{children:"Value"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--output_dir"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"generated/llama3_7b_simple"})}),(0,s.jsx)(n.td,{children:"Directory to store output traces."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--output_name"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"workload.%d.et"})}),(0,s.jsxs)(n.td,{children:["Output filename pattern (",(0,s.jsx)(n.code,{children:"%d"})," = shard index)."]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"--dp"})," / ",(0,s.jsx)(n.code,{children:"--tp"})," / ",(0,s.jsx)(n.code,{children:"--pp"})," / ",(0,s.jsx)(n.code,{children:"--sp"})]}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"1"})}),(0,s.jsx)(n.td,{children:"Data, tensor, pipeline, and sequence parallel degrees (all set to 1 for baseline)."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--model_type"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"llama"})}),(0,s.jsx)(n.td,{children:"Model family for graph generation."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--dmodel"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"4096"})}),(0,s.jsx)(n.td,{children:"Hidden size per transformer layer."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--head"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"32"})}),(0,s.jsx)(n.td,{children:"Number of attention heads."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--kvhead"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"8"})}),(0,s.jsx)(n.td,{children:"Number of key-value heads (for GQA structure)."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--dff"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"11008"})}),(0,s.jsx)(n.td,{children:"Feed-forward hidden dimension."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--seq"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"2048"})}),(0,s.jsx)(n.td,{children:"Sequence length."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--batch"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"4"})}),(0,s.jsx)(n.td,{children:"Global batch size."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--num_stacks"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"32"})}),(0,s.jsx)(n.td,{children:"Transformer depth (number of layers)."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--mixed_precision"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"True"})}),(0,s.jsx)(n.td,{children:"Enables FP16 precision for faster generation and lower memory."})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"--chakra_schema_version"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"v0.0.4"})}),(0,s.jsx)(n.td,{children:"Schema version for Astra-Sim compatibility."})]})]})]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:["Note: ",(0,s.jsx)(n.code,{children:"--micro_batch"})," is not set (defaults to ",(0,s.jsx)(n.code,{children:"--batch"}),"). MoE parameters are not used in this configuration."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"22-astra-sim-analytical-simulation-and-integration",children:"2.2 ASTRA-Sim Analytical Simulation and Integration"}),"\n",(0,s.jsxs)(n.p,{children:["We run ",(0,s.jsx)(n.strong,{children:"ASTRA-Sim"})," with STG-generated traces to evaluate distributed training behavior."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Simulator:"})," ",(0,s.jsx)(n.a,{href:"https://github.com/astra-sim/astra-sim",children:"ASTRA-Sim"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Backend:"})," Analytical (congestion-aware)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Cluster preset:"})," ",(0,s.jsx)(n.code,{children:"hgx_h100_2gpu"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Input:"})," STG-generated ",(0,s.jsx)(n.strong,{children:"Chakra ET"})," + ",(0,s.jsx)(n.strong,{children:"communicator"})]}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"setup-astra-sim--installation",children:"Setup ASTRA-Sim \u2014 Installation"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Clone Repository from Astra-sim\ngit clone git@github.com:astra-sim/astra-sim.git  \nASTRA_SIM=$(realpath ./astra-sim)  \ncd ${ASTRA_SIM}  \ngit submodule update --init --recursive  \n"})}),"\n",(0,s.jsx)(n.p,{children:"Use Docker"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Build Docker Image\ndocker build -t astra-sim:latest -f Dockerfile .\n# Run Docker Container\ndocker run -it --name astra-sim-latest  --shm-size=8g astra-sim:latest bash\n"})}),"\n",(0,s.jsx)(n.h4,{id:"build-astra-sim",children:"Build ASTRA-sim"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Compile Program\n\n# Analytical Network Backend\n./build/astra_analytical/build.sh\n\n# Once built, the executable ${ASTRA_SIM_BIN} is located at:\nASTRA_SIM_BIN=${ASTRA_SIM}/build/astra_analytical/build/bin/AstraSim_Analytical_Congestion_Aware\n"})}),"\n",(0,s.jsx)(n.h4,{id:"run-astra-sim",children:"Run ASTRA-sim"}),"\n",(0,s.jsx)(n.p,{children:"Run simulations by passing the required aruguments:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"${ASTRA_SIM_BIN} \\\n  --workload-configuration=${WORKLOAD_CONFIG} \\\n  --system-configuration=${SYSTEM_CONFIG} \\\n  --network-configuration=${NETWORK_CONFIG} \\\n  --remote-memory-configuration=${REMOTE_MEMORY_CONFIG} \\\n  --comm-group-configuration=${COMM_GROUP_CONFIG}\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Configs"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Workload: ",(0,s.jsx)(n.code,{children:"symbolic_tensor_graph/generated/llama3_7b_dp2/workload"})]}),"\n",(0,s.jsxs)(n.li,{children:["System: ",(0,s.jsx)(n.code,{children:"inputs/system/analytical/hgx_h100_2gpu.json"})]}),"\n",(0,s.jsxs)(n.li,{children:["Network: ",(0,s.jsx)(n.code,{children:"inputs/network/hgx_h100_2gpu.yml"})]}),"\n",(0,s.jsxs)(n.li,{children:["Remote Memory: ",(0,s.jsx)(n.code,{children:"examples/remote_memory/analytical/no_memory_expansion.json"})]}),"\n",(0,s.jsxs)(n.li,{children:["Communicator: ",(0,s.jsx)(n.code,{children:"symbolic_tensor_graph/generated/llama3_7b_dp2/comm_group.json"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Run Command Example"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"build/astra_analytical/build/bin/AstraSim_Analytical_Congestion_Aware \\\n  --workload-configuration=/app/tools/symbolic_tensor_graph/generated/llama3_7b_dp2/workload \\\n  --comm-group-configuration=/app/tools/symbolic_tensor_graph/generated/llama3_7b_dp2/comm_group.json \\\n  --system-configuration=inputs/system/analytical/hgx_h100_2gpu.json \\\n  --network-configuration=inputs/network/hgx_h100_2gpu.yml \\\n  --remote-memory-configuration=examples/remote_memory/analytical/no_memory_expansion.json\n"})}),"\n",(0,s.jsx)(n.h2,{id:"benchmark-reference--mlperf-power",children:"Benchmark Reference \u2014 MLPerf Power"}),"\n",(0,s.jsxs)(n.p,{children:["To guide evaluation, we align with the ",(0,s.jsx)(n.a,{href:"https://ieeexplore.ieee.org/abstract/document/10946778",children:(0,s.jsx)(n.strong,{children:"MLPerf Power"})})," methodology."]}),"\n",(0,s.jsx)(n.h2,{id:"licenses",children:"Licenses"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"ASTRA-Sim"})," \u2014 Released under the ",(0,s.jsx)(n.strong,{children:"BSD 3-Clause License"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Symbolic Tensor Graph (STG)"})," \u2014 Released under the ",(0,s.jsx)(n.strong,{children:"MIT License"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Both projects are fully open-source and publicly available on GitHub.",(0,s.jsx)(n.br,{}),"\n","This artifact leverages their official repositories without modifying any core functionality, ensuring reproducibility and alignment with upstream implementations."]}),"\n",(0,s.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://ieeexplore.ieee.org/document/10818209",children:"PCCL: Power-Aware Collective Communication"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/unslothai/unsloth",children:"Unsloth"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/astra-sim",children:"ASTRA-Sim"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/astra-sim/symbolic_tensor_graph",children:"Symbolic Tensor Graph"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://ieeexplore.ieee.org/abstract/document/10946778",children:"MLPerf"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},5745:(e,n,i)=>{i.d(n,{A:()=>r});const r=i.p+"assets/images/top10ops-5a155e25f52fef17fa38f57e476d498c.png"},6210:(e,n,i)=>{i.d(n,{A:()=>r});const r=i.p+"assets/files/power_log-68968e1a4253934f9958d8e9ce944154.csv"},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>a});var r=i(6540);const s={},l=r.createContext(s);function t(e){const n=r.useContext(l);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),r.createElement(l.Provider,{value:n},e.children)}}}]);