---
sidebar_position: 2
---

## Core Reasoning Breakthroughs
- **Language Models Are Few-Shot Learners** — Brown et al., 2020. [arXiv](https://arxiv.org/abs/2005.14165)
- **Language Models Are Zero-Shot Reasoners** — Kojima et al., 2022. [arXiv](https://arxiv.org/abs/2205.11916)
- **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models** — Wei et al., 2022. [arXiv](https://arxiv.org/abs/2201.11903)
- **Automatic Chain-of-Thought Prompting in Large Language Models** — Zhang et al., 2022. [arXiv](https://arxiv.org/abs/2210.03493)
- **Self-Consistency Improves Chain-of-Thought Reasoning in Language Models** — Wang et al., 2022. [arXiv](https://arxiv.org/abs/2203.11171)
- **Finetuned Language Models Are Zero-Shot Learners** — Wei et al., 2021. [arXiv](https://arxiv.org/abs/2109.01652)
- **STaR: Self-Taught Reasoner** — Zelikman et al., 2022. [arXiv](https://arxiv.org/abs/2203.14465)
- **Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking** — Zelikman et al., 2024. [arXiv](https://arxiv.org/abs/2403.09629)
- **Large Language Models Are Contrastive Reasoners** — Yao, 2024. [arXiv](https://arxiv.org/abs/2403.08211)

## Prompt Engineering & Optimization
- **Language Models Are Human-Level Prompt Engineers** — Zhou et al., 2022. [arXiv](https://arxiv.org/abs/2211.01910)
- **Meta Prompting for AGI Systems** — Zhang, 2023. [arXiv](https://arxiv.org/abs/2311.11482)
- **Large Language Models as Optimizers** — Yang et al., 2023. [arXiv](https://arxiv.org/abs/2309.03409)
- **AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts** — Shin et al., 2020. [arXiv](https://arxiv.org/abs/2010.15980)
- **Prefix-Tuning: Optimizing Continuous Prompts for Generation** — Li & Liang, 2021. [arXiv](https://arxiv.org/abs/2101.00190)
- **Active Prompting with Chain-of-Thought for Large Language Models** — Diao et al., 2023. [arXiv](https://arxiv.org/abs/2302.12246)
- **Guiding Large Language Models via Directional Stimulus Prompting** — Li et al., 2024. [arXiv](https://arxiv.org/abs/2302.11520)
- **Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL** — Sun, Hüyük & van der Schaar, ICLR 2024. [OpenReview](https://openreview.net/forum?id=1b7KCQFqYb)
- **Reinforcement Learning in the Era of LLMs: What Is Essential?** — Sun, 2023. [arXiv](https://arxiv.org/abs/2310.06147)
- **Deep Reinforcement Learning from Human Preferences** — Christiano et al., 2017. [arXiv](https://arxiv.org/abs/1706.03741)

## Multi-Step & Tool-Augmented Reasoning
- **ReAct: Synergizing Reasoning and Acting in Language Models** — Yao et al., 2022. [arXiv](https://arxiv.org/abs/2210.03629)
- **ART: Automatic Multi-Step Reasoning and Tool-Use for Large Language Models** — Paranjape et al., 2023. [arXiv](https://arxiv.org/abs/2303.09014)
- **Tree of Thoughts: Deliberate Problem Solving with Large Language Models** — Yao et al., 2024. [arXiv](https://arxiv.org/abs/2305.10601)
- **Large Language Model Guided Tree-of-Thought** — Long, 2023. [arXiv](https://arxiv.org/abs/2305.08291)
- **Graph of Thoughts: Solving Elaborate Problems with Large Language Models** — Besta et al., 2023. [arXiv](https://arxiv.org/abs/2308.09687)
- **MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in LLMs** — Liu et al., 2023. [arXiv](https://arxiv.org/abs/2308.09729)
- **GraphReader: Building Graph-Based Agents to Enhance Long-Context Abilities of LLMs** — Li et al., 2024. [arXiv](https://arxiv.org/abs/2406.14550)
- **GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks** — Liu et al., WWW 2023. [ACM DL](https://dl.acm.org/doi/10.1145/3543507.3583340)
- **PAL: Program-Aided Language Models** — Gao et al., ICML 2023. [PMLR](https://proceedings.mlr.press/v202/gao23d.html)

## Evaluation & Cognitive Inspiration
- **Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models** — Mondorf & Plank, 2024. [arXiv](https://arxiv.org/abs/2404.01869)
- **Accessible Summary of GPT-3 Experiments** — OpenAI, 2020. [PDF](https://splab.sdu.edu.cn/GPT3.pdf)
- **Neural Mechanisms of Human Decision-Making** — Busemeyer et al., 2020. [Springer](https://link.springer.com/article/10.3758/s13415-020-00842-0)
- **Neuroscience-Inspired Artificial Intelligence** — Hassabis et al., 2017. [PubMed](https://pubmed.ncbi.nlm.nih.gov/28728020/)
- **Matthew Botvinick’s Neuro-Inspired AI Research** — [Google Scholar Profile](https://scholar.google.com/citations?user=eM916YMAAAAJ&hl=en)
